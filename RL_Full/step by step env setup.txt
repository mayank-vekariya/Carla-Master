Full step sequence to create virtual env with Python 3.9
to Run Pytorch CUDA (GPU support), Carla 0.9.15 and StableBaselines3

1. create venv
conda create --name py39 python=3.9

2. Install Pytorch as shown in https://pytorch.org/get-started/locally/
when CUDA 11.8 was allowed. Note, CUDA 11.8 was installed prior to this from NVIDIA website 

conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

3. tested for GPU visibility by Pytorch here - ok

4. install Carla by pip (conda did not have Carla and was giving an error)
pip install carla==0.9.15

5. tested GPU visibility again - ok

6. install stable-baselines3
pip install stable-baselines3[extra]
This changed numpy version from v2.. to 1.26

7. checked GPU with torch - ok 

Key packages after the install:
Carla 0.9.15
numpy 1.26.4
opencv-python 4.10.0.84
pygame 2.6.1
torch 2.5.1
torchaudio 2.5.1
torchvision 0.20.1

8. Install TensorFlow - simple to only apply trained model rather than training
python -m pip install "tensorflow<2.11"

9. Tested torch can see GPU again - ok

10. ran train.py - it was ok but SB3 gave warning that better to run in CPU mode:
C:\ProgramData\miniconda3\envs\py39\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.

